---
title: "Flannery Depression Project"
author: "Kate & Jessica WITH JOHN"
date: "May 24, 2017"
output: html_document
---

Load required packages
```{r Load Required Packages, message=FALSE, warning=FALSE, include=FALSE}
## Load required packages ##
packages <-  c("lme4", "nlme", "ggplot2", "zoo", "dplyr", "tidyr", "knitr",
              "parallel", "data.table", "lubridate", "data.table", "stringr", "summarytools")
if (length(setdiff(packages, rownames(installed.packages()))) > 0) {
  install.packages(setdiff(packages, rownames(installed.packages())))  
}
lapply(packages, library, character.only = TRUE)
```


Load behavioral data
```{r Behavior, message=FALSE, warning=FALSE, include=FALSE}
redcapData <- read.csv(paste0("/Volumes/psych-cog/dsnlab/TAG/behavior/Questionnaires/Confidential/redcap_dates.csv"), header = TRUE, stringsAsFactors = FALSE)
redcapData_dob<-redcapData %>%
  select(dob,subject_spit_id) %>%
  filter(!dob=="")
redcapData_sessiondates<-redcapData %>%
  select(sa_date,sb_date,subject_spit_id) %>%
  filter(!sa_date=="")
redcap_cleaned<-merge(redcapData_sessiondates,redcapData_dob) %>%
  mutate(tagid=substring(subject_spit_id,first=4,last=length(subject_spit_id)))%>%
  filter(!subject_spit_id=="TAG_001P") %>%
  mutate(tagid=ifelse(nchar(tagid)==4,substring(subject_spit_id,first=5,last=length(subject_spit_id)),tagid)) %>%
  mutate(tagid=sprintf("TAG%03d",as.integer(tagid))) %>%
  select(-subject_spit_id)

CESDC<-fread(paste0("/Volumes/psych-cog/dsnlab/TAG/bids_data/derivatives/Jessica_Depression/FLUX2018/CESDC_Wave1.csv")) %>%
  mutate(sub=paste0("sub-",tagid)) %>%
  select(sub, CES_DC_total, CES_DC_mean) %>%
arrange(sub)
# glimpse(SCARED)
# class(SCARED)
# names(SCARED)
# summary(SCARED)
# view(dfSummary(CESDC))

SCARED<-fread(paste0("/Volumes/psych-cog/dsnlab/TAG/bids_data/derivatives/Jessica_Depression/FLUX2018/SCARED_Wave1.csv")) %>%
  mutate(sub=paste0("sub-",tagid)) %>%
  select(sub, SCARED_mean,	SCARED_ptsd_mean,	SCARED_anxiety_mean) %>%
  arrange(sub)
# glimpse(SCARED)
# class(SCARED)
# names(SCARED)
# summary(SCARED)
# view(dfSummary(SCARED))


# CTQ<-fread(paste0("/Volumes/psych-cog/dsnlab/TAG/bids_data/derivatives/Jessica_Depression/FLUX2018/CTQ_Wave1.csv")) %>%
#   mutate(sub=paste0("sub-",tagid)) %>%
#   select(sub, c(73:84)) %>%
#   arrange(sub)

library(purrr)
Dep_Anx <- list(CESDC, SCARED) %>%
  reduce(full_join, by= "sub") 



```
#mock PCA
http://rfunctions.blogspot.com/2015/01/pca-principal-component-analysis.html 
```{r}
library("vegan")
library("FactoMineR")
library("factoextra")
library(gplots)

reduced_data <- na.omit(Dep_Anx)
reduced_data <- as_data_frame(reduced_data)

#write.csv(reduced_data, "reduced_data.csv")
# Install packages.

# install.packages("rgl")
# install.packages("devtools")

# Load packages.

library(rgl)

# Install another package using "devtools".

library(devtools)
# install_github("ggbiplot", "vqv")
library(ggbiplot)

# str(reduced_data)
reduced_data$CES_DC_total<-  as.numeric(reduced_data$CES_DC_total)
ir.pca <- prcomp(reduced_data[,c(2:6)], center = TRUE, scale. = TRUE)
# ir.pca <- prcomp(reduced_data[,c(3:6, 13:18)], center = TRUE, scale. = TRUE)
ir.pca
summary(ir.pca)
loadings <- ir.pca$rotation
scores <- ir.pca$x
correlations <- t(loadings)*ir.pca$sdev

plot(ir.pca, type = "l",main="")

source ('http://www.davidzeleny.net/anadat-r/doku.php/en:numecolr:evplot?do=export_code&codeblock=1')

ev <- ir.pca$sdev^2
evplot(ev)
library(ggplot2)
ggbiplot(ir.pca, choices=c(1,2), obs.scale = 1, var.scale = 1)

# ggbiplot(ir.pca,choices=c(1,2), groups=CES_DC_total[,2] obs.scale = 1, var.scale = 1, ellipse = TRUE)

plot3d(scores[,1:3],size=2.5)
text3d(loadings[,1:3], texts=rownames(loadings), col="red")
coords <- NULL
for (i in 1:nrow(loadings)) {
  coords <- rbind(coords, rbind(c(0,0,0),loadings[i,1:3]))}
lines3d(coords, col="red", lwd=4)

#merge PCA 1 into redcued data set for mood variable
scores <- tbl_df(scores)
library(tibble)
scores_2 <- rownames_to_column(scores, var = "ID")

PCA_combined<- scores_2 %>% 
  bind_cols(reduced_data)

write.csv(PCA_combined, "PCA_combined.csv")

```

Filter sublist
```{r}
sublist<-sublist %>%
  filter(!sub=="sub-TAG000") %>%
  mutate(sub=as.character(sub))
  
```

Get timecourses
```{r}
numcores<-detectCores()[1]
scrubbingThreshold<-.2
sub_base_dir="/Volumes/psych-cog/dsnlab/TAG/TAG_BIDS/derivatives/rsfMRI_preproc_noFDscrub/rsfMRI_preproc_noFDscrub/"
parcellation_list_dir='/projects/dsnlab/tag/TAG_scripts/sMRI/templates/lists/'
# https://surfer.nmr.mgh.harvard.edu/fswiki/FsTutorial/AnatomicalROI/FreeSurferColorLUT
jessparcels<-as.data.frame(rbind("aseg_18","aseg_54","aseg_17","aseg_53","lh.L_a24_ROI","rh.R_a24_ROI")) %>%
   mutate(parcel_name=.[[1]]) %>%
  select(parcel_name)
rois<-bind_rows(jessparcels)

colnames(rois)<-"parcel_name"
  
# rsfcMRI_subjects="/Volumes/TDS/bids_data/derivatives/rsfMRI_preproc/"
# # create sub list based on folders within the freesurfer subjects folder
# subs<-list.files(path = rsfcMRI_subjects, pattern = "sub")

collectAndCorTimecourses <- function(sub, parcels, scrubbingThreshold, sub_base_dir) {
  #below makes a df with every parcel file location, that then reads in the data from that parcel.
  #result is a long data frame with indexes within each parcel (e.g. volume number 1:514)
  timecourses <- data.frame(file_location=paste0(sub_base_dir,sub,"/",sub,".results/timecourses/",sub,'_',parcels$parcel_name,'.txt'),
                            sub=sub,
                            parcel=parcels$parcel_name,
                            stringsAsFactors=F) %>%
    group_by(sub,parcel) %>% do({
      timecourse<-try(fread(.$file_location, stringsAsFactors=F))
      if('try-error' %in% class(timecourse)) timecourse <- data.frame(NA)
      timecourse
    }) %>%
    mutate(index=1:n()) %>% filter(!is.na(V1))
  sub_dir <- paste0(sub_base_dir,sub,"/",sub,".results/")
  #get the motion information and censor properly
  fdfile <- data.frame(motion=read.table(paste0(sub_dir,"motion_",sub,"_enorm.1D"))$V1) %>%
    mutate(index=1:n(),
           censor_raw=motion>scrubbingThreshold, #censor if over the threshold
           censor_1after=censor_raw | lag(censor_raw,1, default=F), #censor 1 after any censored vols
           censor=censor_1after | (lead(censor_1after,1, default=F) & lag(censor_1after,1, default=F))) #censor any vols between censored vols
  #timecourse length == motion data length error checking
  fdlength <- dim(fdfile)[1]
  nada <- timecourses %>% group_by(parcel) %>%
    summarize(n=n()) %>% group_by(parcel) %>%
    do(thing=if(.$n != fdlength) stop(paste0('fdfile and timecourse ARE NOT SAME LENGTH!!!',
                                             sub, ' ', .$parcel, '\n')))
  #get a summary of motion for filtering later, and just for our info
  motiondata <- summarize(fdfile,
                          Blurps=sum(censor_raw),
                          Numcensored=sum(censor))
  #remove censored volumes
  timecourses_censored <- left_join(timecourses, select(fdfile,index,censor)) %>% filter(!censor)
  #more summary info for filtering subjects later
  motiondata$Framesremaining <- timecourses_censored %>% group_by(parcel) %>% 
    summarize(frames_remaining=n()) %>% distinct(frames_remaining) %>%
    unlist  
  #make the timecourse data nice for correlations
  timecourses_censored_w <- timecourses_censored %>% 
    select(sub, index, parcel, V1) %>% 
    spread(parcel,V1) %>% ungroup %>% select(-index, -sub)
  #correlate!
  CorrelationMatrix<-cor(timecourses_censored_w)
  #just take the bottom triangle
  CorrelationMatrix[upper.tri(CorrelationMatrix, diag=TRUE)] <- NA
  #this gets the names for the rows and columns and assigns each cor value
  #a name that is the combination of the row and column.
  CorrDF <- as.data.frame(CorrelationMatrix) %>% #matrix colnames become df column names
    mutate(var2=rownames(CorrelationMatrix)) %>% #add a column for matrix row names
    gather(var1, cor, -var2) %>% #make wide cor mat long, but keep indexed by matrix row name
    filter(!is.na(cor)) %>% #remove NA (upper tri) rows
    unite(coi, var1, var2) #unite the row and col names, now next to each other, into a single name.
  ## The CorrDF data frame now looks like, for example:
  # key                         cor
  # ---                         -----
  # lh.Parcel_1_lh.Parcel_10    0.338
  ##
  # now we want to add in our summary timecourse info re motion etc, so we just 
  # add columns to the correlation data frame, and turn it into a data table for
  # efficiency later on.
  subjDF <- CorrDF %>% mutate(sub=sub, 
                              Blurps=motiondata$Blurps,
                              Numcensored=motiondata$Numcensored,
                              Framesremaining=motiondata$Framesremaining) %>% as.data.table
  # subjDF <- subjDF %>%
  #   filter(grepl("aseg", coi))
}

system.time(jess_cois <- mclapply(as.list(sublist$sub),
                                    collectAndCorTimecourses, 
                                    parcels=rois,
                                    scrubbingThreshold=scrubbingThreshold, 
                                    sub_base_dir=sub_base_dir,
                                    mc.cores=1))
print(object.size(jess_cois), quote = FALSE, units = "Mb")

# bind list of data.tables into one long data.table and filter by frames remaining (< 5 mins)
system.time(jess_coisDT <- do.call(bind_rows, jess_cois) %>% 
              filter(Framesremaining >= 385) %>%
              select(-Blurps, -Numcensored, -Framesremaining) %>%  #we don't need these columns anymore
              as.data.table)
print(object.size(jess_coisDT), quote = FALSE, units = "Mb") #much smaller than the list of data.tables
rm(jess_cois);gc() #remove list, and garbage collect
save(jess_coisDT,file = "/Volumes/psych-cog/dsnlab/TAG/TAG_BIDS/derivatives/Jessica_Depression/jess_coisDT.RDS")
```

IN PROG: Analysis 
```{r}
rerun_models=TRUE

jess_cois<-distinct(jess_coisDT, coi)

if(rerun_models){
  system.time(
    jess_models<-mclapply(
      X=as.list(jess_cois$coi), 
      demodata=CESDC,
      coidata=jess_coisDT,
      mc.cores=numcores,
      FUN=function(coi_name, demodata, coidata){
        adf<-merge(as.data.table(filter(coidata,coi==coi_name)),
                   demodata,
                   by='sub',
                   allow.cartesian=T)
        null_mod=(lme(cor ~ 1,
                      method="ML",
                      random = ~1|sub,
                      data=(adf %>%
                           filter(!is.na(CES_DC_total)))))
        depression_mod=(lme(cor ~ CES_DC_total,
                         method="ML",
                         random = ~1|sub,
                         data=(adf %>%
                           filter(!is.na(CES_DC_total)))))
        mod_comp<-anova(null_mod,depression_mod)
        if (mod_comp$'p-value'[2]<.05 &
            mod_comp$AIC[2]<mod_comp$AIC[1]){
          coiname<- as.character(coi_name)
          chisq <- mod_comp[2,8]
          pval <- round(mod_comp[2,9],4)
          AIC <- mod_comp[2,4]
          nullAIC <- mod_comp[1,4]
          mod <- list(depression_mod)
          mod_type <- "depression model"
          cbind(coiname,chisq,pval,AIC,nullAIC,mod_type,mod)
          retDF<-as.data.table(retDF)
        } else {
          coiname= as.character(coi_name)
          chisq <- "NA"
          pval <- "NA"
          AIC <- "NA"
          nullAIC <- mod_comp[1,4]
          mod <- "NA"
          mod_type <- "null model"
          retDF<-cbind(coiname,chisq,pval,AIC,nullAIC,mod_type,mod)
          as.data.table(retDF)
        }
      }
    ))
  print(object.size(jess_models), units='Mb')
  jess_modelsDT <- bind_rows(jess_models)
  print(object.size(jess_modelsDT), units='Mb')
  rm(jess_models);gc()
  saveRDS(jess_modelsDT, paste0("/Volumes/psych-cog/dsnlab/TAG/TAG_BIDS/derivatives/Jessica_Depression/jess_modelsDT.RDS"))
} else {
  jess_modelsDT <- readRDS(paste0("/Volumes/psych-cog/dsnlab/TAG/TAG_BIDS/derivatives/Jessica_Depression/jess_modelsDT.RDS"))
}
```